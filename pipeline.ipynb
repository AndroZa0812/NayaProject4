{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, AdaBoostClassifier\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.base import BaseEstimator\n",
    "from sklearn.base import TransformerMixin\n",
    "from sklearn.pipeline import FunctionTransformer\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from sklearn.preprocessing import TargetEncoder\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.discriminant_analysis import StandardScaler\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read Test+train Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Education</th>\n",
       "      <th>JoiningYear</th>\n",
       "      <th>City</th>\n",
       "      <th>PaymentTier</th>\n",
       "      <th>Age</th>\n",
       "      <th>Gender</th>\n",
       "      <th>EverBenched</th>\n",
       "      <th>ExperienceInCurrentDomain</th>\n",
       "      <th>id</th>\n",
       "      <th>Race</th>\n",
       "      <th>LeaveOrNot</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1847</th>\n",
       "      <td>Bachelors</td>\n",
       "      <td>2016</td>\n",
       "      <td>Bangalore</td>\n",
       "      <td>3</td>\n",
       "      <td>27.0</td>\n",
       "      <td>Male</td>\n",
       "      <td>Yes</td>\n",
       "      <td>4</td>\n",
       "      <td>1847</td>\n",
       "      <td>white</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2905</th>\n",
       "      <td>Bachelors</td>\n",
       "      <td>2012</td>\n",
       "      <td>Bangalore</td>\n",
       "      <td>3</td>\n",
       "      <td>28.0</td>\n",
       "      <td>Male</td>\n",
       "      <td>No</td>\n",
       "      <td>4</td>\n",
       "      <td>2905</td>\n",
       "      <td>white</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4610</th>\n",
       "      <td>Bachelors</td>\n",
       "      <td>2015</td>\n",
       "      <td>Pune</td>\n",
       "      <td>3</td>\n",
       "      <td>26.0</td>\n",
       "      <td>Female</td>\n",
       "      <td>No</td>\n",
       "      <td>2</td>\n",
       "      <td>4610</td>\n",
       "      <td>white</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2228</th>\n",
       "      <td>Bachelors</td>\n",
       "      <td>2012</td>\n",
       "      <td>Bangalore</td>\n",
       "      <td>3</td>\n",
       "      <td>29.0</td>\n",
       "      <td>Male</td>\n",
       "      <td>No</td>\n",
       "      <td>1</td>\n",
       "      <td>2228</td>\n",
       "      <td>black</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Bachelors</td>\n",
       "      <td>2016</td>\n",
       "      <td>Bangalore</td>\n",
       "      <td>3</td>\n",
       "      <td>24.0</td>\n",
       "      <td>Male</td>\n",
       "      <td>No</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>white</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Education  JoiningYear       City  PaymentTier   Age  Gender  \\\n",
       "1847  Bachelors         2016  Bangalore            3  27.0    Male   \n",
       "2905  Bachelors         2012  Bangalore            3  28.0    Male   \n",
       "4610  Bachelors         2015       Pune            3  26.0  Female   \n",
       "2228  Bachelors         2012  Bangalore            3  29.0    Male   \n",
       "5     Bachelors         2016  Bangalore            3  24.0    Male   \n",
       "\n",
       "     EverBenched  ExperienceInCurrentDomain    id   Race  LeaveOrNot  \n",
       "1847         Yes                          4  1847  white           0  \n",
       "2905          No                          4  2905  white           0  \n",
       "4610          No                          2  4610  white           1  \n",
       "2228          No                          1  2228  black           0  \n",
       "5             No                          0     5  white           0  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_path = 'X_train.csv'\n",
    "y_train_path = 'y_train.csv'\n",
    "X_test_path = 'X_test.csv'\n",
    "\n",
    "# Read the csv files\n",
    "X_train = pd.read_csv(X_train_path, index_col=0)\n",
    "y_train = pd.read_csv(y_train_path, index_col=0)\n",
    "X_test = pd.read_csv(X_test_path, index_col=0)\n",
    "\n",
    "# Join the train datasets\n",
    "full_train_ds = X_train.join(y_train)\n",
    "full_train_ds.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Literal\n",
    "from sklearn.base import BaseEstimator\n",
    "from sklearn.compose import make_column_transformer\n",
    "\n",
    "\n",
    "class DummyEncoder(BaseEstimator, TransformerMixin):\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        return pd.get_dummies(X, drop_first=True)\n",
    "\n",
    "class CustomLabelEncoder(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, mapping):\n",
    "        self.mapping = mapping\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    def transform(self, X):\n",
    "        return X.map(self.mapping)\n",
    "\n",
    "def drop_bad_columns(X: pd.DataFrame):\n",
    "    return X.dropna().copy()\n",
    "\n",
    "class DropDuplicates(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, subset):\n",
    "        self.subset = subset\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    def transform(self, X):\n",
    "        return X.drop_duplicates(subset=self.subset)\n",
    "\n",
    "class DataFrameSelector(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, attribute_names):\n",
    "        self.attribute_names = attribute_names\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    def transform(self, X):\n",
    "        return X[self.attribute_names]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Unable to configure output for DummyEncoder() because `set_output` is not available.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mc:\\Dev\\Naya\\classification\\Classification Project\\pipeline.ipynb Cell 5\u001b[0m line \u001b[0;36m1\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Dev/Naya/classification/Classification%20Project/pipeline.ipynb#X13sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m ct\u001b[39m.\u001b[39mset_output(transform\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mpandas\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Dev/Naya/classification/Classification%20Project/pipeline.ipynb#X13sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m dummy_encoder \u001b[39m=\u001b[39mmake_column_transformer((DummyEncoder(), [\u001b[39m'\u001b[39m\u001b[39mEverBenched\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mGender\u001b[39m\u001b[39m'\u001b[39m]))\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Dev/Naya/classification/Classification%20Project/pipeline.ipynb#X13sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m dummy_encoder\u001b[39m.\u001b[39;49mset_output(transform\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mpandas\u001b[39;49m\u001b[39m'\u001b[39;49m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Dev/Naya/classification/Classification%20Project/pipeline.ipynb#X13sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m numeric_transformer \u001b[39m=\u001b[39m make_column_transformer(\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Dev/Naya/classification/Classification%20Project/pipeline.ipynb#X13sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m     (SimpleImputer(strategy\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mmedian\u001b[39m\u001b[39m\"\u001b[39m), num_attrs),\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Dev/Naya/classification/Classification%20Project/pipeline.ipynb#X13sZmlsZQ%3D%3D?line=19'>20</a>\u001b[0m     (StandardScaler(), num_attrs),\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Dev/Naya/classification/Classification%20Project/pipeline.ipynb#X13sZmlsZQ%3D%3D?line=20'>21</a>\u001b[0m )\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Dev/Naya/classification/Classification%20Project/pipeline.ipynb#X13sZmlsZQ%3D%3D?line=21'>22</a>\u001b[0m numeric_transformer\u001b[39m.\u001b[39mset_output(transform\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mpandas\u001b[39m\u001b[39m'\u001b[39m)\n",
      "File \u001b[1;32mc:\\Python\\Python10\\lib\\site-packages\\sklearn\\compose\\_column_transformer.py:316\u001b[0m, in \u001b[0;36mColumnTransformer.set_output\u001b[1;34m(self, transform)\u001b[0m\n\u001b[0;32m    308\u001b[0m transformers \u001b[39m=\u001b[39m (\n\u001b[0;32m    309\u001b[0m     trans\n\u001b[0;32m    310\u001b[0m     \u001b[39mfor\u001b[39;00m _, trans, _ \u001b[39min\u001b[39;00m chain(\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    313\u001b[0m     \u001b[39mif\u001b[39;00m trans \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m {\u001b[39m\"\u001b[39m\u001b[39mpassthrough\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mdrop\u001b[39m\u001b[39m\"\u001b[39m}\n\u001b[0;32m    314\u001b[0m )\n\u001b[0;32m    315\u001b[0m \u001b[39mfor\u001b[39;00m trans \u001b[39min\u001b[39;00m transformers:\n\u001b[1;32m--> 316\u001b[0m     _safe_set_output(trans, transform\u001b[39m=\u001b[39;49mtransform)\n\u001b[0;32m    318\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mremainder \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m {\u001b[39m\"\u001b[39m\u001b[39mpassthrough\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mdrop\u001b[39m\u001b[39m\"\u001b[39m}:\n\u001b[0;32m    319\u001b[0m     _safe_set_output(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mremainder, transform\u001b[39m=\u001b[39mtransform)\n",
      "File \u001b[1;32mc:\\Python\\Python10\\lib\\site-packages\\sklearn\\utils\\_set_output.py:295\u001b[0m, in \u001b[0;36m_safe_set_output\u001b[1;34m(estimator, transform)\u001b[0m\n\u001b[0;32m    292\u001b[0m     \u001b[39mreturn\u001b[39;00m\n\u001b[0;32m    294\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mhasattr\u001b[39m(estimator, \u001b[39m\"\u001b[39m\u001b[39mset_output\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[1;32m--> 295\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    296\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mUnable to configure output for \u001b[39m\u001b[39m{\u001b[39;00mestimator\u001b[39m}\u001b[39;00m\u001b[39m because `set_output` \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    297\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mis not available.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    298\u001b[0m     )\n\u001b[0;32m    299\u001b[0m \u001b[39mreturn\u001b[39;00m estimator\u001b[39m.\u001b[39mset_output(transform\u001b[39m=\u001b[39mtransform)\n",
      "\u001b[1;31mValueError\u001b[0m: Unable to configure output for DummyEncoder() because `set_output` is not available."
     ]
    }
   ],
   "source": [
    "rnd_state = 10\n",
    "\n",
    "# Define the pipeline\n",
    "num_attrs = ['JoiningYear', 'PaymentTier', 'Age', 'ExperienceInCurrentDomain']\n",
    "cat_attrs = ['Education', 'City', 'Gender', 'EverBenched', 'Race']\n",
    "education_order = [\"Bachelors\", \"Masters\", \"PHD\"]\n",
    "\n",
    "# Adding a scaler to the pipeline\n",
    "ct = ColumnTransformer([\n",
    "        ('TargetEncoder', TargetEncoder(), ['City', 'Race']),\n",
    "        ('EducationLevelEncoder', OrdinalEncoder(categories=[education_order]), ['Education']),\n",
    "    ], remainder='passthrough', verbose_feature_names_out=False)\n",
    "ct.set_output(transform='pandas')\n",
    "\n",
    "dummy_encoder =make_column_transformer((DummyEncoder(), ['EverBenched', 'Gender']))\n",
    "dummy_encoder.set_output(transform='pandas')\n",
    "\n",
    "numeric_transformer = make_column_transformer(\n",
    "    (SimpleImputer(strategy=\"median\"), num_attrs),\n",
    "    (StandardScaler(), num_attrs),\n",
    ")\n",
    "numeric_transformer.set_output(transform='pandas')\n",
    "\n",
    "full_pipeline = Pipeline([\n",
    "    ('ColumnTransformers', ct),\n",
    "    ('DummyEncoder',dummy_encoder),\n",
    "    ('NumericTransformer', numeric_transformer),\n",
    "])\n",
    "\n",
    "# # Fit and transform the data\n",
    "X_train_prepared = full_pipeline.fit_transform(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining the classifiers and their hyperparameters\n",
    "classifiers = {\n",
    "    'Logistic Regression': {\n",
    "        'model': LogisticRegression(random_state=rnd_state),\n",
    "        'params': {\n",
    "            'C': [0.3, 0.5, 1],\n",
    "            'penalty': ['l1', 'l2']\n",
    "        }\n",
    "    },\n",
    "    'Decision Tree': {\n",
    "        'model': DecisionTreeClassifier(random_state=rnd_state),\n",
    "        'params': {\n",
    "            'max_depth': [7, 8, 9],\n",
    "            'min_samples_split': [14, 15, 16]\n",
    "        }\n",
    "    },\n",
    "    'KNN': {\n",
    "        'model': KNeighborsClassifier(),\n",
    "        'params': {\n",
    "            'n_neighbors': [3]\n",
    "        }\n",
    "    },\n",
    "    'Gaussian Naive Bayes': {\n",
    "        'model': GaussianNB(),\n",
    "        'params': {}\n",
    "    },\n",
    "    'Random Forest': {\n",
    "        'model': RandomForestClassifier(random_state=rnd_state),\n",
    "        'params': {\n",
    "            'n_estimators': [100, 110],\n",
    "            'max_depth': [15],\n",
    "            'min_samples_split': [11, 12],\n",
    "            'min_samples_leaf': [3, 4],\n",
    "            'max_features': ['auto'],\n",
    "            'bootstrap': [False]\n",
    "        }\n",
    "    },\n",
    "    'Gradient Boosting': {\n",
    "        'model': GradientBoostingClassifier(random_state=rnd_state),\n",
    "        'params': {\n",
    "            'n_estimators': [120, 130],\n",
    "            'learning_rate': [0.03],\n",
    "            'max_depth': [5],\n",
    "            'subsample': [0.9],\n",
    "            'min_samples_split': [3, 4, 5]\n",
    "        }\n",
    "    },\n",
    "    'AdaBoost': {\n",
    "        'model': AdaBoostClassifier(random_state=rnd_state),\n",
    "        'params': {\n",
    "            'n_estimators': [50],\n",
    "            'learning_rate': [1.2, 1.3],\n",
    "            'algorithm' : ['SAMME', 'SAMME.R']\n",
    "        }\n",
    "    },\n",
    "    'XGBoost': {\n",
    "        'model': xgb.XGBClassifier(use_label_encoder=False, eval_metric='logloss'),\n",
    "        'params': {\n",
    "            'n_estimators': [110, 120],\n",
    "            'learning_rate': [0.04, 0.05],\n",
    "            'max_depth': [4, 5],\n",
    "            'gamma': [0.1],\n",
    "            'subsample': [0.9, 1.0],\n",
    "            'colsample_bytree': [0.8, 0.9]\n",
    "        }\n",
    "    },\n",
    "    'LightGBM': {\n",
    "        'model': lgb.LGBMClassifier(force_row_wise=True, random_state=rnd_state),\n",
    "        'params': {\n",
    "            'n_estimators': [70, 80, 90],\n",
    "            'learning_rate': [0.3, 0.4],\n",
    "            'max_depth': [2,3, 4]\n",
    "        }\n",
    "    }\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
