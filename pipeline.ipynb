{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, AdaBoostClassifier\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.base import BaseEstimator\n",
    "from sklearn.base import TransformerMixin\n",
    "from sklearn.pipeline import FunctionTransformer\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from sklearn.preprocessing import TargetEncoder\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read Test+train Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_path = 'X_train.csv'\n",
    "y_train_path = 'y_train.csv'\n",
    "X_test_path = 'X_test.csv'\n",
    "\n",
    "# Read the csv files\n",
    "X_train = pd.read_csv(X_train_path, index_col=0)\n",
    "y_train = pd.read_csv(y_train_path, index_col=0)\n",
    "X_test = pd.read_csv(X_test_path, index_col=0)\n",
    "\n",
    "# Join the train datasets\n",
    "full_train_ds = X_train.join(y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DummyEncoder(BaseEstimator, TransformerMixin):\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        return pd.get_dummies(X, drop_first=True)\n",
    "\n",
    "def drop_bad_columns(X: pd.DataFrame):\n",
    "    return X.dropna().copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'ColumnTransformer' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Dev\\Naya\\classification\\Classification Project\\pipeline.ipynb Cell 5\u001b[0m line \u001b[0;36m9\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Dev/Naya/classification/Classification%20Project/pipeline.ipynb#X13sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m education_order \u001b[39m=\u001b[39m [\u001b[39m\"\u001b[39m\u001b[39mBachelors\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mMasters\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mPHD\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Dev/Naya/classification/Classification%20Project/pipeline.ipynb#X13sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m \u001b[39m# Adding a scaler to the pipeline\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Dev/Naya/classification/Classification%20Project/pipeline.ipynb#X13sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m ct \u001b[39m=\u001b[39m ColumnTransformer([\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Dev/Naya/classification/Classification%20Project/pipeline.ipynb#X13sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m         (\u001b[39m'\u001b[39m\u001b[39mTargetEncoder\u001b[39m\u001b[39m'\u001b[39m, TargetEncoder(), [\u001b[39m'\u001b[39m\u001b[39mCity\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mRace\u001b[39m\u001b[39m'\u001b[39m]),\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Dev/Naya/classification/Classification%20Project/pipeline.ipynb#X13sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m         (\u001b[39m'\u001b[39m\u001b[39mEducationLevelEncoder\u001b[39m\u001b[39m'\u001b[39m, OrdinalEncoder(categories\u001b[39m=\u001b[39m[education_order]), [\u001b[39m'\u001b[39m\u001b[39mEducation\u001b[39m\u001b[39m'\u001b[39m]),\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Dev/Naya/classification/Classification%20Project/pipeline.ipynb#X13sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m         (\u001b[39m'\u001b[39m\u001b[39mGenderEncoder\u001b[39m\u001b[39m'\u001b[39m, DummyEncoder(), [\u001b[39m'\u001b[39m\u001b[39mGender\u001b[39m\u001b[39m'\u001b[39m]),\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Dev/Naya/classification/Classification%20Project/pipeline.ipynb#X13sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m         \u001b[39m# ('scaler', StandardScaler(), ['Age', 'Years of Experience', 'height', 'weight', 'professionalism']),\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Dev/Naya/classification/Classification%20Project/pipeline.ipynb#X13sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m     ], remainder\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mpassthrough\u001b[39m\u001b[39m'\u001b[39m, verbose_feature_names_out\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Dev/Naya/classification/Classification%20Project/pipeline.ipynb#X13sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m ct\u001b[39m.\u001b[39mset_output(transform\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mpandas\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Dev/Naya/classification/Classification%20Project/pipeline.ipynb#X13sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m full_pipeline \u001b[39m=\u001b[39m ColumnTransformer([\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Dev/Naya/classification/Classification%20Project/pipeline.ipynb#X13sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m     (\u001b[39m'\u001b[39m\u001b[39mDropNaTransformer\u001b[39m\u001b[39m'\u001b[39m, FunctionTransformer(drop_bad_columns)),\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Dev/Naya/classification/Classification%20Project/pipeline.ipynb#X13sZmlsZQ%3D%3D?line=19'>20</a>\u001b[0m     (\u001b[39m'\u001b[39m\u001b[39mColumnTransformers\u001b[39m\u001b[39m'\u001b[39m, ct),\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Dev/Naya/classification/Classification%20Project/pipeline.ipynb#X13sZmlsZQ%3D%3D?line=20'>21</a>\u001b[0m ])\n",
      "\u001b[1;31mNameError\u001b[0m: name 'ColumnTransformer' is not defined"
     ]
    }
   ],
   "source": [
    "rnd_state = 10\n",
    "\n",
    "# Define the pipeline\n",
    "num_attribs = ['JoiningYear', 'PaymentTier', 'Age', 'ExperienceInCurrentDomain']\n",
    "cat_attribs = ['Education', 'City', 'Gender', 'EverBenched', 'Race']\n",
    "education_order = [\"Bachelors\", \"Masters\", \"PHD\"]\n",
    "\n",
    "# Adding a scaler to the pipeline\n",
    "ct = ColumnTransformer([\n",
    "        ('TargetEncoder', TargetEncoder(), ['City', 'Race']),\n",
    "        ('EducationLevelEncoder', OrdinalEncoder(categories=[education_order]), ['Education']),\n",
    "        ('GenderEncoder', DummyEncoder(), ['Gender']),\n",
    "        # ('scaler', StandardScaler(), ['Age', 'Years of Experience', 'height', 'weight', 'professionalism']),\n",
    "    ], remainder='passthrough', verbose_feature_names_out=False)\n",
    "\n",
    "ct.set_output(transform='pandas')\n",
    "\n",
    "full_pipeline = ColumnTransformer([\n",
    "    ('DropNaTransformer', FunctionTransformer(drop_bad_columns)),\n",
    "    ('ColumnTransformers', ct),\n",
    "])\n",
    "\n",
    "# Fit and transform the data\n",
    "X_train_prepared = full_pipeline.fit_transform(X_train)\n",
    "X_test_prepared = full_pipeline.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining the classifiers and their hyperparameters\n",
    "classifiers = {\n",
    "    'Logistic Regression': {\n",
    "        'model': LogisticRegression(random_state=rnd_state),\n",
    "        'params': {\n",
    "            'C': [0.3, 0.5, 1],\n",
    "            'penalty': ['l1', 'l2']\n",
    "        }\n",
    "    },\n",
    "    'Decision Tree': {\n",
    "        'model': DecisionTreeClassifier(random_state=rnd_state),\n",
    "        'params': {\n",
    "            'max_depth': [7, 8, 9],\n",
    "            'min_samples_split': [14, 15, 16]\n",
    "        }\n",
    "    },\n",
    "    'KNN': {\n",
    "        'model': KNeighborsClassifier(),\n",
    "        'params': {\n",
    "            'n_neighbors': [3]\n",
    "        }\n",
    "    },\n",
    "    'Gaussian Naive Bayes': {\n",
    "        'model': GaussianNB(),\n",
    "        'params': {}\n",
    "    },\n",
    "    'Random Forest': {\n",
    "        'model': RandomForestClassifier(random_state=rnd_state),\n",
    "        'params': {\n",
    "            'n_estimators': [100, 110],\n",
    "            'max_depth': [15],\n",
    "            'min_samples_split': [11, 12],\n",
    "            'min_samples_leaf': [3, 4],\n",
    "            'max_features': ['auto'],\n",
    "            'bootstrap': [False]\n",
    "        }\n",
    "    },\n",
    "    'Gradient Boosting': {\n",
    "        'model': GradientBoostingClassifier(random_state=rnd_state),\n",
    "        'params': {\n",
    "            'n_estimators': [120, 130],\n",
    "            'learning_rate': [0.03],\n",
    "            'max_depth': [5],\n",
    "            'subsample': [0.9],\n",
    "            'min_samples_split': [3, 4, 5]\n",
    "        }\n",
    "    },\n",
    "    'AdaBoost': {\n",
    "        'model': AdaBoostClassifier(random_state=rnd_state),\n",
    "        'params': {\n",
    "            'n_estimators': [50],\n",
    "            'learning_rate': [1.2, 1.3],\n",
    "            'algorithm' : ['SAMME', 'SAMME.R']\n",
    "        }\n",
    "    },\n",
    "    'XGBoost': {\n",
    "        'model': xgb.XGBClassifier(use_label_encoder=False, eval_metric='logloss'),\n",
    "        'params': {\n",
    "            'n_estimators': [110, 120],\n",
    "            'learning_rate': [0.04, 0.05],\n",
    "            'max_depth': [4, 5],\n",
    "            'gamma': [0.1],\n",
    "            'subsample': [0.9, 1.0],\n",
    "            'colsample_bytree': [0.8, 0.9]\n",
    "        }\n",
    "    },\n",
    "    'LightGBM': {\n",
    "        'model': lgb.LGBMClassifier(force_row_wise=True, random_state=rnd_state),\n",
    "        'params': {\n",
    "            'n_estimators': [70, 80, 90],\n",
    "            'learning_rate': [0.3, 0.4],\n",
    "            'max_depth': [2,3, 4]\n",
    "        }\n",
    "    }\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
