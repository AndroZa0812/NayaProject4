{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, AdaBoostClassifier\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.base import BaseEstimator\n",
    "from sklearn.base import TransformerMixin\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class DataFrameSelector(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, attribute_names):\n",
    "        self.attribute_names = attribute_names\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    def transform(self, X):\n",
    "        return X[self.attribute_names]\n",
    "\n",
    "class DropDuplicates(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, subset):\n",
    "        self.subset = subset\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    def transform(self, X):\n",
    "        return X.drop_duplicates(subset=self.subset)\n",
    "\n",
    "class DropMissingValues(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    def transform(self, X):\n",
    "        return X.dropna()\n",
    "\n",
    "class CustomLabelEncoder(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, mapping):\n",
    "        self.mapping = mapping\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    def transform(self, X):\n",
    "        return X.map(self.mapping)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnd_state = 10\n",
    "\n",
    "# Define the pipeline\n",
    "num_attribs = ['JoiningYear', 'PaymentTier', 'Age', 'ExperienceInCurrentDomain']\n",
    "cat_attribs = ['Education', 'City', 'Gender', 'EverBenched', 'Race']\n",
    "\n",
    "num_pipeline = Pipeline([\n",
    "    ('selector', DataFrameSelector(num_attribs)),\n",
    "    ('imputer', SimpleImputer(strategy='median')),\n",
    "    ('std_scaler', StandardScaler()),\n",
    "])\n",
    "\n",
    "cat_pipeline = Pipeline([\n",
    "    ('selector', DataFrameSelector(cat_attribs)),\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('one_hot_encoder', OneHotEncoder(sparse=False)),\n",
    "])\n",
    "\n",
    "full_pipeline = ColumnTransformer([\n",
    "    ('num', num_pipeline, num_attribs),\n",
    "    ('cat', cat_pipeline, cat_attribs),\n",
    "])\n",
    "\n",
    "# Fit and transform the data\n",
    "X_train_prepared = full_pipeline.fit_transform(X_train)\n",
    "X_test_prepared = full_pipeline.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining the classifiers and their hyperparameters\n",
    "classifiers = {\n",
    "    'Logistic Regression': {\n",
    "        'model': LogisticRegression(random_state=rnd_state),\n",
    "        'params': {\n",
    "            'C': [0.3, 0.5, 1],\n",
    "            'penalty': ['l1', 'l2']\n",
    "        }\n",
    "    },\n",
    "    'Decision Tree': {\n",
    "        'model': DecisionTreeClassifier(random_state=rnd_state),\n",
    "        'params': {\n",
    "            'max_depth': [7, 8, 9],\n",
    "            'min_samples_split': [14, 15, 16]\n",
    "        }\n",
    "    },\n",
    "    'KNN': {\n",
    "        'model': KNeighborsClassifier(),\n",
    "        'params': {\n",
    "            'n_neighbors': [3]\n",
    "        }\n",
    "    },\n",
    "    'Gaussian Naive Bayes': {\n",
    "        'model': GaussianNB(),\n",
    "        'params': {}\n",
    "    },\n",
    "    'Random Forest': {\n",
    "        'model': RandomForestClassifier(random_state=rnd_state),\n",
    "        'params': {\n",
    "            'n_estimators': [100, 110],\n",
    "            'max_depth': [15],\n",
    "            'min_samples_split': [11, 12],\n",
    "            'min_samples_leaf': [3, 4],\n",
    "            'max_features': ['auto'],\n",
    "            'bootstrap': [False]\n",
    "        }\n",
    "    },\n",
    "    'Gradient Boosting': {\n",
    "        'model': GradientBoostingClassifier(random_state=rnd_state),\n",
    "        'params': {\n",
    "            'n_estimators': [120, 130],\n",
    "            'learning_rate': [0.03],\n",
    "            'max_depth': [5],\n",
    "            'subsample': [0.9],\n",
    "            'min_samples_split': [3, 4, 5]\n",
    "        }\n",
    "    },\n",
    "    'AdaBoost': {\n",
    "        'model': AdaBoostClassifier(random_state=rnd_state),\n",
    "        'params': {\n",
    "            'n_estimators': [50],\n",
    "            'learning_rate': [1.2, 1.3],\n",
    "            'algorithm' : ['SAMME', 'SAMME.R']\n",
    "        }\n",
    "    },\n",
    "    'XGBoost': {\n",
    "        'model': xgb.XGBClassifier(use_label_encoder=False, eval_metric='logloss'),\n",
    "        'params': {\n",
    "            'n_estimators': [110, 120],\n",
    "            'learning_rate': [0.04, 0.05],\n",
    "            'max_depth': [4, 5],\n",
    "            'gamma': [0.1],\n",
    "            'subsample': [0.9, 1.0],\n",
    "            'colsample_bytree': [0.8, 0.9]\n",
    "        }\n",
    "    },\n",
    "    'LightGBM': {\n",
    "        'model': lgb.LGBMClassifier(force_row_wise=True, random_state=rnd_state),\n",
    "        'params': {\n",
    "            'n_estimators': [70, 80, 90],\n",
    "            'learning_rate': [0.3, 0.4],\n",
    "            'max_depth': [2,3, 4]\n",
    "        }\n",
    "    }\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline(\n",
    "\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
