{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, AdaBoostClassifier\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.base import BaseEstimator\n",
    "from sklearn.base import TransformerMixin\n",
    "from sklearn.pipeline import FunctionTransformer\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from sklearn.preprocessing import TargetEncoder\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "class DummyEncoder(BaseEstimator, TransformerMixin):\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        return pd.get_dummies(X, drop_first=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_bad_columns(X: pd.DataFrame):\n",
    "    return X.dropna().copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "rnd_state = 10\n",
    "\n",
    "# Define the pipeline\n",
    "num_attribs = ['JoiningYear', 'PaymentTier', 'Age', 'ExperienceInCurrentDomain']\n",
    "cat_attribs = ['Education', 'City', 'Gender', 'EverBenched', 'Race']\n",
    "education_order = [\"Bachelors\", \"Masters\", \"PHD\"]\n",
    "\n",
    "# Adding a scaler to the pipeline\n",
    "ct = ColumnTransformer([\n",
    "        ('TargetEncoder', TargetEncoder(), ['City', 'Race']),\n",
    "        ('EducationLevelEncoder', OrdinalEncoder(categories=[education_order]), ['Education']),\n",
    "        ('GenderEncoder', DummyEncoder(categories=[['Male', 'Female']]), ['Gender']),\n",
    "        # ('scaler', StandardScaler(), ['Age', 'Years of Experience', 'height', 'weight', 'professionalism']),\n",
    "    ], remainder='passthrough', verbose_feature_names_out=False)\n",
    "\n",
    "ct.set_output(transform='pandas')\n",
    "\n",
    "full_pipeline = ColumnTransformer([\n",
    "    ('DropNaTransformer', FunctionTransformer(drop_bad_columns)),\n",
    "    ('ColumnTransformers', ct),\n",
    "])\n",
    "\n",
    "# Fit and transform the data\n",
    "X_train_prepared = full_pipeline.fit_transform(X_train)\n",
    "X_test_prepared = full_pipeline.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining the classifiers and their hyperparameters\n",
    "classifiers = {\n",
    "    'Logistic Regression': {\n",
    "        'model': LogisticRegression(random_state=rnd_state),\n",
    "        'params': {\n",
    "            'C': [0.3, 0.5, 1],\n",
    "            'penalty': ['l1', 'l2']\n",
    "        }\n",
    "    },\n",
    "    'Decision Tree': {\n",
    "        'model': DecisionTreeClassifier(random_state=rnd_state),\n",
    "        'params': {\n",
    "            'max_depth': [7, 8, 9],\n",
    "            'min_samples_split': [14, 15, 16]\n",
    "        }\n",
    "    },\n",
    "    'KNN': {\n",
    "        'model': KNeighborsClassifier(),\n",
    "        'params': {\n",
    "            'n_neighbors': [3]\n",
    "        }\n",
    "    },\n",
    "    'Gaussian Naive Bayes': {\n",
    "        'model': GaussianNB(),\n",
    "        'params': {}\n",
    "    },\n",
    "    'Random Forest': {\n",
    "        'model': RandomForestClassifier(random_state=rnd_state),\n",
    "        'params': {\n",
    "            'n_estimators': [100, 110],\n",
    "            'max_depth': [15],\n",
    "            'min_samples_split': [11, 12],\n",
    "            'min_samples_leaf': [3, 4],\n",
    "            'max_features': ['auto'],\n",
    "            'bootstrap': [False]\n",
    "        }\n",
    "    },\n",
    "    'Gradient Boosting': {\n",
    "        'model': GradientBoostingClassifier(random_state=rnd_state),\n",
    "        'params': {\n",
    "            'n_estimators': [120, 130],\n",
    "            'learning_rate': [0.03],\n",
    "            'max_depth': [5],\n",
    "            'subsample': [0.9],\n",
    "            'min_samples_split': [3, 4, 5]\n",
    "        }\n",
    "    },\n",
    "    'AdaBoost': {\n",
    "        'model': AdaBoostClassifier(random_state=rnd_state),\n",
    "        'params': {\n",
    "            'n_estimators': [50],\n",
    "            'learning_rate': [1.2, 1.3],\n",
    "            'algorithm' : ['SAMME', 'SAMME.R']\n",
    "        }\n",
    "    },\n",
    "    'XGBoost': {\n",
    "        'model': xgb.XGBClassifier(use_label_encoder=False, eval_metric='logloss'),\n",
    "        'params': {\n",
    "            'n_estimators': [110, 120],\n",
    "            'learning_rate': [0.04, 0.05],\n",
    "            'max_depth': [4, 5],\n",
    "            'gamma': [0.1],\n",
    "            'subsample': [0.9, 1.0],\n",
    "            'colsample_bytree': [0.8, 0.9]\n",
    "        }\n",
    "    },\n",
    "    'LightGBM': {\n",
    "        'model': lgb.LGBMClassifier(force_row_wise=True, random_state=rnd_state),\n",
    "        'params': {\n",
    "            'n_estimators': [70, 80, 90],\n",
    "            'learning_rate': [0.3, 0.4],\n",
    "            'max_depth': [2,3, 4]\n",
    "        }\n",
    "    }\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
